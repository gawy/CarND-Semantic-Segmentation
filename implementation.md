
## Plan

* ~~Basic structure~~
* Way to visualize loss over epochs
* Save loss history to compare between experiments
* Model optimization
    * ~~L2 regularization~~
    * L2 with coefficients (from project support materials)
    * Skip layers
    * Advanced Faster-RCNN (from kaggle competition winners)


Log:
- adding stop gradient propagation increased training spead and same accuracy can be reached in shorter time (3epochs, lr=1e-3)


